{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dba8af5f",
   "metadata": {},
   "source": [
    "Imports and setups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0431da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '../scripts'))\n",
    "from scripts.sentiment_analysis import SentimentAnalyzer\n",
    "from scripts.config import DATA_PATHS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fc427",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db71e983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully loaded 1200 reviews\n",
      "‚úÖ Loaded 1200 reviews\n",
      "üìä Banks: ['Commercial bank of Ethiopia' 'Bank of Abyssinia' 'Dashen Bank']\n"
     ]
    }
   ],
   "source": [
    "# Initialize analyzer\n",
    "analyzer = SentimentAnalyzer()\n",
    "\n",
    "# Use your data loader\n",
    "df = analyzer.load_data()\n",
    "\n",
    "# Check if data loaded successfully\n",
    "if df is None:\n",
    "    print(\"‚ùå Cannot continue - no data loaded\")\n",
    "else:\n",
    "    print(f\"‚úÖ Loaded {len(df)} reviews\")\n",
    "    print(\"üìä Banks:\", df['bank_name'].unique())\n",
    "    analyzer.df = df  # Important: assign to analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5bfa69",
   "metadata": {},
   "source": [
    "Initialize Modules and Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b545356a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Using TextBlob for sentiment analysis (faster setup)\n",
      "Applying sentiment analysis to real data...\n",
      "‚úÖ Sentiment analysis complete!\n",
      "‚úÖ Sentiment analysis complete!\n",
      "üìà Sentiment distribution:\n",
      "sentiment_label\n",
      "POSITIVE    632\n",
      "NEUTRAL     459\n",
      "NEGATIVE    109\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Only run if data loaded successfully\n",
    "if df is not None:\n",
    "    analyzer.initialize_sentiment_model()\n",
    "    df_with_sentiment = analyzer.analyze_real_data()\n",
    "    \n",
    "    print(\"‚úÖ Sentiment analysis complete!\")\n",
    "    print(\"üìà Sentiment distribution:\")\n",
    "    print(df_with_sentiment['sentiment_label'].value_counts())\n",
    "else:\n",
    "    df_with_sentiment = None\n",
    "    print(\"‚ùå Skipping analysis - no data available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c33273c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make plots a bit prettier\n",
    "sns.set(style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (8, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa177d68",
   "metadata": {},
   "source": [
    "Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "273a89bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Text preprocessing complete\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CBE ·ã≠·àà·ã´·àç·ç¢</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>it's special for me</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Make it user friendly.</td>\n",
       "      <td>2</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              review_text  rating rating_label\n",
       "0               CBE ·ã≠·àà·ã´·àç·ç¢       5     positive\n",
       "1     it's special for me       5     positive\n",
       "2  Make it user friendly.       2     negative"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if df_with_sentiment is not None:\n",
    "    def rating_to_label(r):\n",
    "        if r <= 2: return \"negative\"\n",
    "        elif r == 3: return \"neutral\"\n",
    "        else: return \"positive\"\n",
    "\n",
    "    df_with_sentiment[\"rating_label\"] = df_with_sentiment[\"rating\"].apply(rating_to_label)\n",
    "    df_with_sentiment[\"clean_text\"] = df_with_sentiment[\"review_text\"].str.lower()\n",
    "    \n",
    "    print(\"‚úÖ Text preprocessing complete\")\n",
    "    display(df_with_sentiment[[\"review_text\", \"rating\", \"rating_label\"]].head(3))\n",
    "else:\n",
    "    print(\"‚ùå Skipping preprocessing - no data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48099a33",
   "metadata": {},
   "source": [
    "Frequency Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98f2a2ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Frequency analysis complete\n"
     ]
    }
   ],
   "source": [
    "if df_with_sentiment is not None:\n",
    "    try:\n",
    "        freq_df = analyzer.frequency_test()\n",
    "        # ... rest of your frequency analysis code\n",
    "        print(\"‚úÖ Frequency analysis complete\")\n",
    "    except Exception as e:\n",
    "        print(\"‚ö†Ô∏è Frequency analysis skipped:\", e)\n",
    "else:\n",
    "    print(\"‚ùå Skipping frequency analysis - no data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac37439f",
   "metadata": {},
   "source": [
    "Aggregation and Themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9f19fa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TASK 2: SENTIMENT BY BANK & RATING ===\n",
      "                      bank_name  rating  sentiment_score  review_count\n",
      "0             Bank of Abyssinia       1        -0.099326           134\n",
      "1             Bank of Abyssinia       2         0.096214            15\n",
      "2             Bank of Abyssinia       3         0.119560            22\n",
      "3             Bank of Abyssinia       4         0.292164            23\n",
      "4             Bank of Abyssinia       5         0.429618           206\n",
      "5   Commercial bank of Ethiopia       1        -0.042707            56\n",
      "6   Commercial bank of Ethiopia       2         0.099280            13\n",
      "7   Commercial bank of Ethiopia       3         0.144211            23\n",
      "8   Commercial bank of Ethiopia       4         0.241601            40\n",
      "9   Commercial bank of Ethiopia       5         0.433438           268\n",
      "10                  Dashen Bank       1        -0.124915            73\n",
      "11                  Dashen Bank       2         0.119978            18\n",
      "12                  Dashen Bank       3         0.217305            22\n",
      "13                  Dashen Bank       4         0.413520            26\n",
      "14                  Dashen Bank       5         0.455383           261\n",
      "\n",
      "=== TASK 2: TOP KEYWORDS BY BANK ===\n",
      "\n",
      "--- Commercial bank of Ethiopia ---\n",
      "Keywords: ['app', 'application', 'bank', 'best', 'cbe', 'good', 'nice', 'update']\n",
      "\n",
      "--- Bank of Abyssinia ---\n",
      "Keywords: ['app', 'bank', 'banking', 'best', 'boa', 'good', 'mobile', 'work']\n",
      "\n",
      "--- Dashen Bank ---\n",
      "Keywords: ['app', 'bank', 'banking', 'best', 'dashen', 'good', 'super', 'use']\n"
     ]
    }
   ],
   "source": [
    "if df_with_sentiment is not None:\n",
    "    # ‚úÖ TASK 2: Sentiment aggregation\n",
    "    print(\"=== TASK 2: SENTIMENT BY BANK & RATING ===\")\n",
    "    bank_rating_sentiment = df_with_sentiment.groupby(['bank_name', 'rating']).agg({\n",
    "        'sentiment_score': 'mean',\n",
    "        'review_text': 'count'\n",
    "    }).rename(columns={'review_text': 'review_count'}).reset_index()\n",
    "    print(bank_rating_sentiment)\n",
    "\n",
    "    # ‚úÖ TASK 2: Thematic analysis\n",
    "    print(\"\\n=== TASK 2: TOP KEYWORDS BY BANK ===\")\n",
    "    for bank in df_with_sentiment['bank_name'].unique():\n",
    "        bank_reviews = df_with_sentiment[df_with_sentiment['bank_name'] == bank]\n",
    "        print(f\"\\n--- {bank} ---\")\n",
    "        \n",
    "        from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "        tfidf = TfidfVectorizer(stop_words='english', max_features=8)\n",
    "        tfidf_matrix = tfidf.fit_transform(bank_reviews['clean_text'])\n",
    "        feature_names = tfidf.get_feature_names_out()\n",
    "        print(\"Keywords:\", list(feature_names))\n",
    "else:\n",
    "    print(\"‚ùå Cannot complete Task 2 - no data available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54665a9a",
   "metadata": {},
   "source": [
    "Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42884d06",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Cannot save file into a non-existent directory: 'data\\processed'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_with_sentiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m     output_file = os.path.join(DATA_PATHS[\u001b[33m'\u001b[39m\u001b[33mprocessed\u001b[39m\u001b[33m'\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mbank_reviews_with_sentiment.csv\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[SAVED] reviews sentiment ‚Üí \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    328\u001b[39m     warnings.warn(\n\u001b[32m    329\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    330\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    331\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    332\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:3989\u001b[39m, in \u001b[36mNDFrame.to_csv\u001b[39m\u001b[34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[39m\n\u001b[32m   3978\u001b[39m df = \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m.to_frame()\n\u001b[32m   3980\u001b[39m formatter = DataFrameFormatter(\n\u001b[32m   3981\u001b[39m     frame=df,\n\u001b[32m   3982\u001b[39m     header=header,\n\u001b[32m   (...)\u001b[39m\u001b[32m   3986\u001b[39m     decimal=decimal,\n\u001b[32m   3987\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m3989\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3990\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3991\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3992\u001b[39m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[43m=\u001b[49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3993\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3994\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3995\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3996\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3997\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4000\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4002\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4003\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4004\u001b[39m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4005\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4006\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[39m, in \u001b[36mDataFrameRenderer.to_csv\u001b[39m\u001b[34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[39m\n\u001b[32m    993\u001b[39m     created_buffer = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    995\u001b[39m csv_formatter = CSVFormatter(\n\u001b[32m    996\u001b[39m     path_or_buf=path_or_buf,\n\u001b[32m    997\u001b[39m     lineterminator=lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1012\u001b[39m     formatter=\u001b[38;5;28mself\u001b[39m.fmt,\n\u001b[32m   1013\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m \u001b[43mcsv_formatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[32m   1017\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[39m, in \u001b[36mCSVFormatter.save\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03mCreate the writer & save.\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    250\u001b[39m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    256\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    258\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[32m    259\u001b[39m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[32m    260\u001b[39m     \u001b[38;5;28mself\u001b[39m.writer = csvlib.writer(\n\u001b[32m    261\u001b[39m         handles.handle,\n\u001b[32m    262\u001b[39m         lineterminator=\u001b[38;5;28mself\u001b[39m.lineterminator,\n\u001b[32m   (...)\u001b[39m\u001b[32m    267\u001b[39m         quotechar=\u001b[38;5;28mself\u001b[39m.quotechar,\n\u001b[32m    268\u001b[39m     )\n\u001b[32m    270\u001b[39m     \u001b[38;5;28mself\u001b[39m._save()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:749\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    747\u001b[39m \u001b[38;5;66;03m# Only for write methods\u001b[39;00m\n\u001b[32m    748\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m is_path:\n\u001b[32m--> \u001b[39m\u001b[32m749\u001b[39m     \u001b[43mcheck_parent_directory\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m compression:\n\u001b[32m    752\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m compression != \u001b[33m\"\u001b[39m\u001b[33mzstd\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# compression libraries do not like an explicit text-mode\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\ourbarn\\Desktop\\Customer-Experience-Analysis-for-Fintech-Apps\\.venv\\Lib\\site-packages\\pandas\\io\\common.py:616\u001b[39m, in \u001b[36mcheck_parent_directory\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m    614\u001b[39m parent = Path(path).parent\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m parent.is_dir():\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33mrf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCannot save file into a non-existent directory: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparent\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mOSError\u001b[39m: Cannot save file into a non-existent directory: 'data\\processed'"
     ]
    }
   ],
   "source": [
    "if df_with_sentiment is not None:\n",
    "    output_file = os.path.join(DATA_PATHS['processed'], \"bank_reviews_with_sentiment.csv\")\n",
    "    df.to_csv(output_file, index=False, encoding='utf-8')\n",
    "    print(f\"[SAVED] reviews sentiment ‚Üí {output_file}\")\n",
    "else:\n",
    "    print(\"‚ùå Could not save results - no data available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
